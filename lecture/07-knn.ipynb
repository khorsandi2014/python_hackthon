{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn and the K-nearest Neighbor Algorithm\n",
    "\n",
    "In this notebook we'll introduce the `sklearn` package and a few important concepts in machine learning:\n",
    "\n",
    "* Splitting data into test, train, and validation sets.\n",
    "* Fitting models to a dataset.\n",
    "* And using \"Hyperparameters\" to tune models. \n",
    "\n",
    "Lets revisit the example we saw in the first class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "heart_dataset = pd.read_csv('../data/heart-disease.csv')\n",
    "heart_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7540983606557377\n"
     ]
    }
   ],
   "source": [
    "# Split the data into input and labels\n",
    "labels = heart_dataset['target']\n",
    "input_data = heart_dataset.drop(columns=['target'])\n",
    "\n",
    "# Split the data into training and test\n",
    "training_data, validation_data, training_labels, validation_labels = train_test_split(\n",
    "    input_data, \n",
    "    labels, \n",
    "    test_size=0.20\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(training_data, training_labels)\n",
    "\n",
    "# See how it did.\n",
    "print(\"Test accuracy: \", model.score(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLearn's API\n",
    "\n",
    "Scikit learn has a wonderfully unified API that always follows this pattern: \n",
    "\n",
    "* Create a model from a class.\n",
    "    * This is where you set the \"hyperparameters\" of the model.\n",
    "* Call that model's `.fit` method using the training data to train the model.\n",
    "* Call that model's `.score` method to evaluate the model against the validation/test data.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 validation accuracy:  0.5901639344262295\n",
      " 2 validation accuracy:  0.6065573770491803\n",
      " 3 validation accuracy:  0.5737704918032787\n"
     ]
    }
   ],
   "source": [
    "# Lets build multiple models using a few different \"hyperparameters\"\n",
    "model_one = KNeighborsClassifier()\n",
    "model_two = KNeighborsClassifier(weights='distance')\n",
    "model_three = KNeighborsClassifier(n_neighbors=1, weights='distance')\n",
    "\n",
    "for i, model in enumerate([model_one, model_two, model_three]):\n",
    "    model.fit(training_data, training_labels)\n",
    "    print(f' {i+1} validation accuracy: ', model.score(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The K-Nearest Neighbor's Model\n",
    "\n",
    "So what is the actual difference between these three models? How does KNN actually work?\n",
    "\n",
    "KNN is a relatively straightforward model. When you want to make a prediction with KNN you simply compare the item you're making a prediction about to the training dataset using a distance function and based on the class of the \"nearest\" neighbors the model makes a prediction.\n",
    "\n",
    "K is how many neighbors to look at, if k is 5 the model looks at the 5 nearest neighbors and whichever class is most common among those 5 neighbors is the one selected. Lets look at some pictures from the pre-reading (https://towardsdatascience.com/laymans-introduction-to-knn-c793ed392bc2):\n",
    "\n",
    "![](https://miro.medium.com/max/552/1*6YK2xQ4wxBGGrCaegT9JfA.png)\n",
    "\n",
    "![](https://miro.medium.com/max/552/1*z-y9I2aHAGj4GtMI5cR1OA.png)\n",
    "\n",
    "![](https://miro.medium.com/max/552/1*7tSKxmXPca1IlgjRHtwOGg.png)\n",
    "\n",
    "![](https://miro.medium.com/max/552/1*_EYdoVX941aZXa5BH6XnHQ.png)\n",
    "\n",
    "These examples are all in 2-dimensional space, but the algorithm generalizes to n-dimensions (based on the number of features in our training data). \n",
    "\n",
    "K is controlled in `sklearn` by the `n_neighbors` parameter. \n",
    "\n",
    "Another hyperparameter in KNN is the `weights` parameter, which has 3 possible values, from the docs (https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html):\n",
    "\n",
    "* ‘uniform’ : uniform weights. All points in each neighborhood are weighted equally.\n",
    "* ‘distance’ : weight points by the inverse of their distance. in this case, closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "* [callable] : a user-defined function which accepts an array of distances, and returns an array of the same shape containing the weights.\n",
    "\n",
    "Similarly, the distance metric can be provided:\n",
    "\n",
    "> metric: str or callable, default=’minkowski’\n",
    "\n",
    "> the distance metric to use for the tree. The default metric is minkowski, and with p=2 is equivalent to the standard Euclidean metric. See the documentation of DistanceMetric for a list of available metrics. If metric is “precomputed”, X is assumed to be a distance matrix and must be square during fit. X may be a sparse graph, in which case only “nonzero” elements may be considered neighbors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
