{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Apply tree classifiers and learn ensemble techniques such as Bagging, Boosting and RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Let's walk through a simple decision tree. I'll draw one out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brainstorm & Discussion\n",
    "- In what real-life contexts do you think this technique could be useful?\n",
    "- Where do you think it would be less useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Mechanics of Trees\n",
    "I'll draw out a tree in a 2-dimensional space. Let's see how classification and accuracy work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worksheet 1\n",
    "- [Tree Worksheet 1](https://s3-us-west-2.amazonaws.com/ga-dat-2015-suneel/worksheets/Decision+Trees/DT_wksht_2.pdf)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inside the Black Box\n",
    "Let's work through an example and define the procedure.\n",
    "\n",
    "- [Tree Worksheet 2](https://s3-us-west-2.amazonaws.com/ga-dat-2015-suneel/worksheets/Decision+Trees/DT_wksht_3.pdf)\n",
    "\n",
    "### Notes\n",
    "- Gini impurity index\n",
    "- Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem with Trees\n",
    "\n",
    "* Strengths and weaknesses:\n",
    "  * Prone to overfitting, esp. as you make the tree deeper.\n",
    "  * The model is very understandable, and provides clear rules for predictions.\n",
    "  * Flexible with respect to training data (continuous and categorical work great, missing values can be a source of splitting)\n",
    "  * Depending on how big of a tree you want, fitting them can be expensive.\n",
    "  * But... honestly, often they are still much faster than something like a Neural Network.\n",
    "  * Not great at regression.\n",
    "  * Like many learning algorithms, trees perform poorly with small amounts of training data.\n",
    "\n",
    "\n",
    "### Bagging (Bootstrap Aggregation) and Feature Selection\n",
    "\n",
    "* Bagging is sampling with replacement.\n",
    "    * Common to select the same number of samples as the population size, but this is configurable.\n",
    "    * Because it uses replacement, it's quite likely be duplicates.\n",
    "    * Can help reduce overfitting and causes each tree to make different splitting decisions\n",
    "* Feature Selection means at each split we randomly select a list of features that are eligable to be split.\n",
    "    * Common choices for numebr of features are sqrt(n) and log(n)\n",
    "    * Forces each tree to make different splitting decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read & Discuss\n",
    "Read this [Intuitive explanation of Random Forest](https://www.quora.com/How-does-randomization-in-a-random-forest-work/answer/Edwin-Chen-1?share=1&srid=h5QG) and discuss with your group.\n",
    "\n",
    "Separate into pairs and practice explaining to the best of your understanding how Random Forest works.\n",
    "\n",
    "This is a good practie for all the models that you learn going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Random Forest Procedure\n",
    "Let's lay it out. What are the steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pick the number of trees and define their hyperparameters (max depth, min sample split...)\n",
    "1. For each tree, perform bagging to create the sample for that tree. \n",
    "    1. For each tree for each split, randomly sample the available features.\n",
    "    1. Determine the best split given the available features, and split!\n",
    "    1. Repeat A-C until we've got all leaf nodes.\n",
    "1. Repeat 2-5 until we've done all the trees.\n",
    "\n",
    "At classification time, run the new sample through all the trees, and pick the class based on the vote of all the individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's apply what we've learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/breast-cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>...</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "      <th>x24</th>\n",
       "      <th>x25</th>\n",
       "      <th>x26</th>\n",
       "      <th>x27</th>\n",
       "      <th>x28</th>\n",
       "      <th>x29</th>\n",
       "      <th>x30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Diagnosis     x1     x2      x3      x4       x5       x6      x7  \\\n",
       "0    842302         M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517         M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903         M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301         M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        x8  ...    x21    x22     x23     x24     x25     x26     x27     x28  \\\n",
       "0  0.14710  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654   \n",
       "1  0.07017  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n",
       "2  0.12790  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n",
       "3  0.10520  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n",
       "4  0.10430  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n",
       "\n",
       "      x29      x30  \n",
       "0  0.4601  0.11890  \n",
       "1  0.2750  0.08902  \n",
       "2  0.3613  0.08758  \n",
       "3  0.6638  0.17300  \n",
       "4  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Import the `DecisionTreeClassifier` from `sklearn`.\n",
    "2. Look through the documentation page on `sklearn`. What do you notice? What are our dials that we can use to tune the model? Any questions or thoughts?\n",
    "3. Apply the model to the dataset. What are the results?\n",
    "4. Use `train_test_split` multiple times to shuffle the randomness of the split. Each time you shuffle and you run the model, what happens? What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9361702127659575\n",
      "0.9095744680851063\n",
      "0.8936170212765957\n",
      "0.9202127659574468\n",
      "0.925531914893617\n",
      "0.9042553191489362\n",
      "0.925531914893617\n",
      "0.9308510638297872\n",
      "0.9414893617021277\n",
      "0.925531914893617\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Diagnosis', 'ID'])\n",
    "y = df['Diagnosis'] == 'M' # \"True\" will mean malignant, \"False\" will mean begnin\n",
    "\n",
    "for _ in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "    tree = DecisionTreeClassifier()\n",
    "    tree.fit(X_train, y_train)\n",
    "    score = tree.score(X_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing `cross_val_score`\n",
    "\n",
    "- Let's save ourselves some time with this nice `sklearn` utility.\n",
    "- Let's look at the importance of the mean score and the standard deviation of the score. What do they mean and what are each of them important?\n",
    "  * Mean is the average accuracy over different folds of the data.\n",
    "      * Lower values mean we're not generally predicting well.\n",
    "  * Std. gives us an idea about the error bounds of our model (on this data).\n",
    "      * Higher values mean our model has high variance across subsets of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9122807  0.85964912 0.92982456 0.87719298 0.94736842 0.89473684\n",
      " 0.89473684 0.94736842 0.92982456 0.89285714]\n",
      "mean: 0.909\n",
      "Std. Deviation: 0.0282\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(tree, X, y, cv=10)\n",
    "\n",
    "print(scores)\n",
    "print(f\"mean: {np.mean(scores):.3}\")\n",
    "print(f\"Std. Deviation: {np.std(scores):.3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "1. Now apply `RandomForestClassifier`, tune it with the different dials and describe the results.\n",
    "\n",
    "\n",
    "### Notes\n",
    "- Let's examine feature importance. Random forest gives us a nice way to do that, remember?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.87719298 0.92982456 0.94736842 0.98245614 0.96491228\n",
      " 0.94736842 0.98245614 0.92982456 0.98214286]\n",
      "mean: 0.954\n",
      "Std. Deviation: 0.0344\n"
     ]
    }
   ],
   "source": [
    "# One example, but you should try more combinations of different params.\n",
    "# You could even consider a \"grid search\"\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "rf = RandomForestClassifier(min_samples_split=10, max_depth=5, min_samples_leaf=10)\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=10)\n",
    "print(scores)\n",
    "print(f\"mean: {np.mean(scores):.3}\")\n",
    "print(f\"Std. Deviation: {np.std(scores):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
